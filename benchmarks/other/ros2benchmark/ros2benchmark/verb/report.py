# Copyright (C) Acceleration Robotics S.L.U. - All Rights Reserved
#
# Written by V√≠ctor Mayoral-Vilches <victor@accelerationrobotics.com>
# Licensed under the Apache License, Version 2.0

from ros2cli.node.strategy import add_arguments as add_strategy_node_arguments
from ros2cli.node.strategy import NodeStrategy
from ros2benchmark.verb import VerbExtension, Benchmark, run, search_benchmarks
from ros2benchmark.verb.summary import SummaryVerb
import os
import yaml
import pprint
import matplotlib.pyplot as plt
import arrow
import random


class ReportVerb(VerbExtension):
    """
    Generate a markdown report with the results of the benchmarks in the workspace.

    NOTE: each benchmark should follow the specification
    detailed at https://github.com/robotperf/benchmarks/blob/main/benchmarks/README.md
    """ 

    def write_to_file(self, path, content):
        # Create directory structure if it doesn't exist
        directory = os.path.dirname(path)
        if not os.path.exists(directory):
            os.makedirs(directory)
        
        # Open the file and write the content
        with open(path, 'w') as f:
            f.write(content)

    @staticmethod
    def plot_function_values(data_sample):
        """
        Extract the "value" from a data_sample

        :param data_sample: dict with the data
        """
        return data_sample['value']

    @staticmethod
    def plot_function_names(data_sample):
        """
        Extract the "name" from a data_sample

        :param data_sample: dict with the data
        """
        return data_sample['name']

    @staticmethod
    def plot_function_names_forid(data_sample):
        """
        Extract the "name" from a data_sample

        :param data_sample: dict with the data
        """

        return_str = ""         
        # return_str += data_sample['hardware'] + " (" + data_sample['timestampt'] + ")"

        if "ROBOTCORE¬Æ" in data_sample['hardware']:
            return_str += data_sample['hardware'].replace("ROBOTCORE¬Æ", "$\mathbf{ROBOTCORE¬Æ}$")
        else:
            return_str += data_sample['hardware']


        if data_sample['type'].lower() == "grey":
            return_str += "‚ö™"
        elif data_sample['type'].lower() == "black":
            return_str += "‚ö´"
        else:
            return_str += "?"

        return return_str

    @staticmethod
    def plot_data(data, 
                  title,
                  xlabel,
                  ylabel,
                  name_function=plot_function_names,
                  value_function=plot_function_values, 
                  filter=None, 
                  unique=False,
                  sortedata=False, 
                  sortedatareverse=False,
                  filterout=None):
        """
        Plot the data in a bar plot and save it to a file.

        :param data: list of dicts with the data to plot
        :param title: title of the plot
        :param name_function: function to extract the name from the data
        :param value_function: function to extract the value from the data
        :param filter: function to filter the data
        :param unique: if True, only the most recent entry for each 'name', 'hardware', 'type', 'datasource' combination is plotted
        :param sortedata: if True, the data is sorted by value
        :param sortedatareverse: if True, the data is sorted by value in reverse order
        :param filterout: list of tuples (hardware, type) to filter out and not consider
        """

        plotpath = '/tmp/report-' + title + '-latency.png'
        if filter:
            # Filter data using the provided function
            filtered_data = [d for d in data if filter(d)]
        else:
            filtered_data = data

        if unique:
            # Use a dictionary to hold the most recent entry for each 'name', 
            # 'hardware', 'type', 'datasource' combination
            filtered_dict = {}
            for entry in filtered_data:
                name = entry['name'] + entry['hardware'] + entry['type'] + entry['datasource']
            
                # NOTE: condition 1: if not in dict or more recent than the one in the dict
                # if name not in filtered_dict or arrow.get(entry['timestampt'], ['D-M-YYYY', 'YYYY-MM-DD HH:mm:ss']).datetime > arrow.get(filtered_dict[name]['timestampt'], ['D-M-YYYY', 'YYYY-MM-DD HH:mm:ss']).datetime:

                # NOTE: condition 2: if not in dict or lower "value" than the one in the dict
                # not in filterout and greater then 0.001 (heuristic to remove outliers, close to zero)
                if (name not in filtered_dict or entry['value'] < filtered_dict[name]['value']) and (filterout is None or (entry['hardware'], entry['type']) not in filterout) and (entry['value'] > 0.001):
                    filtered_dict[name] = entry

            filtered_data = filtered_dict.values()            

        # order list using "value"
        if sortedata:
            filtered_data = sorted(filtered_data, key=lambda x: x['value'])
        if sortedatareverse:
            filtered_data = sorted(filtered_data, key=lambda x: x['value'], reverse=True)

        # extac
        names = [name_function(d) for d in filtered_data]
        values = [value_function(d) for d in filtered_data]


        # # debug
        # print(names)
        # print(values)
        # # print(filtered_data)
        
        # colors = [plt.cm.viridis(random.random()) for _ in range(len(names))]
        colors = [plt.cm.viridis(random.random(), alpha=0.2 if (data['type'].lower() == "grey") else 1.0) for data in filtered_data]

        # Create a bar plot
        plt.figure(figsize=(10, 5))
        # plt.bar(names, values, color='blue')
        plt.bar(names, values, color=colors)
        plt.title(title)
        plt.xlabel(xlabel)
        plt.ylabel(ylabel)
        plt.xticks(rotation=87)  # Rotate x-axis labels for better visibility

        # Save the figure and close
        plt.savefig(plotpath, bbox_inches='tight')
        plt.close()
        
        return plotpath


    def main(self, *, args):
        # get paths of "benchmark.yaml" files for each benchmark
        benchmark_meta_paths = search_benchmarks()
        list_results = SummaryVerb.preprocess(benchmark_meta_paths)
        list_ids = SummaryVerb.extract_unique_x(list_results, "id")
        alphabetical_list_ids = sorted(list_ids)

        # pprint.pprint(list_results)

        benchmark_id_report = ""
        # Add a title to the report indicating a timestamp of when it was generated
        benchmark_id_report += f"# [RobotPerf](https://robotperf.org/) report (generated on `{arrow.now().format('YYYY-MM-DD HH:mm:ss')}`)\n\n"

        # Generate a Table of Contents
        benchmark_id_report += "## Table of Contents\n"
        benchmark_id_report += "- [Intro](#intro)\n"
        benchmark_id_report += "- [Legend](#legend)\n"
        benchmark_id_report += "- [Benchmark results by `id`](#benchmark-results-by-id)\n"
        for benchmark_id in alphabetical_list_ids:
            benchmark_id_report += "  - [Benchmark `{}`](#benchmark-{})\n".format(benchmark_id, benchmark_id)
        benchmark_id_report += "- [Benchmarking results by `hardware` solution](#benchmarking-results-by-hardware-solution)\n"

        ######################################################
        # 0. Intro and Legend
        ######################################################
        benchmark_id_report += "## Intro\n"

        benchmark_id_report += '[**Benchmark results** ü§ñ](https://github.com/robotperf/benchmarks#benchmarks) | [Benchmark spec üìñ](https://github.com/robotperf/benchmarks/blob/main/benchmarks/README.md) | [*Contributing* üåç](https://github.com/robotperf/benchmarks#contributing) | [`Contact and support` üì®](https://github.com/robotperf/benchmarks#contact-and-support)\n'


        benchmark_id_report += '<a href="https://accelerationrobotics.com/robotperf.php"><img src="https://raw.githubusercontent.com/robotperf/benchmarks/main/imgs/ROBOTPerf.svg" align="left" hspace="8" vspace="2" width="200"></a>'
        benchmark_id_report += 'RobotPerf is an **open reference benchmarking suite that is used to evaluate robotics computing performance** fairly with [ROS 2](https://accelerationrobotics.com/ros.php) as its common baseline, *so that robotic architects can make informed decisions about the hardware and software components of their robotic systems*.\n\n'
        benchmark_id_report += "The project's <ins>mission is to build open, fair and useful robotics benchmarks that are technology agnostic, vendor-neutral and provide unbiased evaluations of robotics computing performance for hardware, software, and services</ins>.  As a reference performance benchmarking suite in robotics, RobotPerf *can be used to evaluate robotics computing performance across compute substratrated including CPUs, GPUs, FPGAs and other compute accelerators*. The benchmarks are designed to be representative of the performance of a robotic system and to be reproducible across different robotic systems. For that, RobotPerf builds on top of ROS 2, the de facto standard for robot application development.\n\n"
        benchmark_id_report += "RobotPerf is a project led by [Acceleration Robotics](https://accelerationrobotics.com/), a company that provides robotics acceleration solutions for the next generation of robots. Refer to the [Benchmark Specification](https://github.com/robotperf/benchmarks/blob/main/benchmarks/README.md) for more details.\n\n"

        # Add a legend
        benchmark_id_report += "### Legend\n"
        benchmark_id_report += "\n"
        benchmark_id_report += "**Metrics**\n"
        benchmark_id_report += "- ‚è±: latency\n"
        benchmark_id_report += "- üì∂: throughput (fps)\n"
        benchmark_id_report += "- ‚ö°: power\n"
        benchmark_id_report += "\n"
        benchmark_id_report += "**Type**\n"
        benchmark_id_report += "- ‚ö™: grey\n"
        benchmark_id_report += "- ‚ö´: black\n"
        benchmark_id_report += "- ‚úã: manual (rosbag directly)\n"
        benchmark_id_report += "\n"
        benchmark_id_report += "**Category**\n"
        benchmark_id_report += "- üìü: edge/embedded\n"
        benchmark_id_report += "- üñ•Ô∏è: workstation\n"
        benchmark_id_report += "- üóÑ: data center\n"
        benchmark_id_report += "- ‚õÖ: cloud targets\n\n"
        
        ######################################################        
        # 1. Print all results for each benchmark
        ######################################################
        benchmark_id_report += "## Benchmark results by `id`\n"

        # unique condition
        unique_condition = True

        for benchmark_id in alphabetical_list_ids:
            
            benchmark_id_report += f"### Benchmark `{benchmark_id}`\n"

            # ## all of it (metric-agnostic)
            # # get body
            # filtered_data = [item for item in list_results if item['id'] == benchmark_id]
            # benchmark_id_report += SummaryVerb.to_markdown_table(filtered_data, benchmark_id)
            # # plot
            # plotpath = (ReportVerb.plot_data(filtered_data, 
            #                                 name_function=ReportVerb.plot_function_names_forid,
            #                                 value_function=ReportVerb.plot_function_values,
            #                                 title=benchmark_id, 
            #                                 unique=False))
            # benchmark_id_report += f"\n![{plotpath}]({plotpath})"


            ## ‚è± latency
            filter_out = [("Kria KR260", "black")]
            filtered_data = [item for item in list_results if (item['id'] == benchmark_id and item['metric'] == "latency")]
            sorted_filtered_data = sorted(filtered_data, key=lambda x: x['value'])
            plotpath = (ReportVerb.plot_data(sorted_filtered_data,
                                             xlabel="Hardware (timestamp)",
                                             ylabel="Latency (ms)",
                                             name_function=ReportVerb.plot_function_names_forid,
                                             value_function=ReportVerb.plot_function_values,
                                             title=benchmark_id + "-latency",
                                             unique=unique_condition,
                                             sortedata=True,
                                             filterout = filter_out))
            benchmark_id_report += f"\n![{plotpath}]({plotpath})\n"
            benchmark_id_report += SummaryVerb.to_markdown_table(sorted_filtered_data, 
                                                                 benchmark_id+"-latency",
                                                                 unique=unique_condition,
                                                                 sortedata=True,
                                                                 filterout = filter_out)

            ## ‚ö° power
            filter_out = []
            filtered_data = [item for item in list_results if (item['id'] == benchmark_id and item['metric'] == "power")]
            sorted_filtered_data = sorted(filtered_data, key=lambda x: x['value'])
            plotpath = (ReportVerb.plot_data(sorted_filtered_data,
                                             xlabel="Hardware (timestamp)",
                                             ylabel="Power (W)",
                                             name_function=ReportVerb.plot_function_names_forid,
                                             value_function=ReportVerb.plot_function_values,
                                             title=benchmark_id + "-power",
                                             unique=unique_condition,
                                             sortedata=True,
                                             filterout = filter_out))
            benchmark_id_report += f"\n![{plotpath}]({plotpath})\n"
            benchmark_id_report += SummaryVerb.to_markdown_table(sorted_filtered_data, 
                                                                 benchmark_id+"-power",
                                                                 unique=unique_condition,
                                                                 sortedata=True,
                                                                 filterout = filter_out)

            ## üì∂ throughput
            filter_out = []
            filtered_data = [item for item in list_results if (item['id'] == benchmark_id and item['metric'] == "throughput")]
            sorted_filtered_data = sorted(filtered_data, key=lambda x: x['value'], reverse=True)
            plotpath = (ReportVerb.plot_data(sorted_filtered_data,
                                             xlabel="Hardware (timestamp)",
                                             ylabel="Throughput (FPS)",
                                             name_function=ReportVerb.plot_function_names_forid,
                                             value_function=ReportVerb.plot_function_values,
                                             title=benchmark_id + "-throughput",
                                             unique=unique_condition,
                                             sortedatareverse=True,
                                             filterout = filter_out))
            benchmark_id_report += f"\n![{plotpath}]({plotpath})\n"
            benchmark_id_report += SummaryVerb.to_markdown_table(sorted_filtered_data, 
                                                                 benchmark_id+"-throughput",
                                                                 unique=unique_condition,
                                                                 sortedatareverse=True,
                                                                 filterout = filter_out)

        benchmark_id_report += f"\n\n"

        ######################################################
        # 2. Print all results grouped by hardware solution, for all of the solutions
        # ######################################################
        benchmark_id_report += "## Benchmarking results by `hardware` solution\n"
        # NOTE: ordered by timestamp and name
        list_hardware = SummaryVerb.extract_unique_x(list_results, "hardware")
        for hw in list_hardware:
            extracted_data = [d for d in list_results if d['hardware'] == hw]
            benchmark_id_report += SummaryVerb.to_markdown_table(extracted_data, hw)
        

        # produce report
        self.write_to_file('/tmp/report.md', benchmark_id_report)
        print("Writing report to /tmp/report.md")
